{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stay Ahead of the Tech CurveSubscribe to My Full-Stack Developer Insights!\n",
      "Embark on a journey through asynchronous programming in Python with this in-depth guide to the asyncio module. Unleash the power of concurrent code execution in your Python applications!\n",
      "Discover the power of parallel processing in Python. Dive deep into multithreading and multiprocessing, learning when and how to use these powerful tools for optimized performance. Get the most out of your Python code!\n",
      "Join a fellow developer on an in-depth exploration of Python web development using Flask and Django, complete with code examples and hands-on insights.\n",
      "Unravel the magic of Python generators to create memory-efficient iterators. Dive deep into Python decorators. Enhance your advanced Python skills and ace efficient programming.\n",
      "Explore the seamless integration of SQLite with Python in our advanced guide. Learn to establish connections, interact with the database, and improve your Python database programming skills.\n",
      "Dive into the world of Python decorators with our comprehensive guide. Learn how to use them to extend your functions, make your code more readable, and give your Python skills a boost!\n",
      "\n",
      "Sarah Perez,Â \t\t\tAmanda Silberling \n",
      "\n",
      "Ivan Mehta \n",
      "\n",
      "Natasha Lomas \n",
      "\n",
      "Anna Heim \n",
      "\n",
      "Kyle Wiggers \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url_list = [\"https://snehasish.dev\",\"https://techcrunch.com\"]\n",
    "\n",
    "for url in url_list:\n",
    "    # Make a request to each url\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all paragraph 'p' tags and print their text\n",
    "    for p_tag in soup.find_all('p'):\n",
    "        print(p_tag.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
